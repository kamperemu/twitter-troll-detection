{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "molecular-worcester",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "shared-attack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Some things even spell check can't fix \", 'just woke up, what an overcast day ', 'RT @wikileaks: DoJ Assistant Attorney Peter Kadzik outed as a mole for Hillary Clinton campaign https://t.co/MNHzJ310Nl https://t.co/uTQF6b…', 'RT @true_pundit: #TruePundit is now back on #Facebook ! Go check us out &amp; give us a like for some exclusive content https://t.co/xuC0vBs3vB…', 'RT @DistantDistant: @Enjoneer01 @Dubzzzinyaface #ItsNotAWasteIf you call shredded animal bits, \"a filler\"']\n",
      "[0, 0, 1, 1, 1]\n",
      "['#TopNews Pressure on Trump likely to be intense at second debate with Clinton', '@gotobekiddingme I tried.....and failed ', \"RT @TelcoJ: Black Trump Representative Brings Down the House on Chicago's WGN | RedState https://t.co/u2eEOraGFO\", \"@TonyWade aww thanks! I don't play harp  I play violin very badly! think I'll stick to singing!when I need a fanclub I'll be onto you ;-)\", \"RT @theolcaper: #ProbableTrumpsTweets I'm not only a client I'm the U.S. President\"]\n",
      "[1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "with open(\"datasets/test.json\", 'r') as f:\n",
    "    tweets = json.load(f)\n",
    "random.shuffle(tweets)\n",
    "train = tweets[:int(round(4*len(tweets)/5))]\n",
    "test = tweets[int(round(4*len(tweets)/5)):len(tweets)]\n",
    "xtrain = []\n",
    "ytrain = []\n",
    "xtest = []\n",
    "ytest = []\n",
    "\n",
    "for tweet in train:\n",
    "    xtrain.append(tweet['content'])\n",
    "    ytrain.append(tweet['label'])\n",
    "    \n",
    "for tweet in test:\n",
    "    xtest.append(tweet['content'])\n",
    "    ytest.append(tweet['label'])\n",
    "\n",
    "    \n",
    "print(xtrain[:5])\n",
    "print(ytrain[:5])\n",
    "print(xtest[:5])\n",
    "print(ytest[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "equal-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessklearn.py file (you are actually supposed to import this but for demonstration i have just put this in)\n",
    "# you can do this by putting the line \"from preprocesssklearn import *\"\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "def removespchar(text):\n",
    "    pattern=r'[^a-zA-Z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text.lower()\n",
    "\n",
    "def stemmer(text):\n",
    "    ps=nltk.porter.PorterStemmer()\n",
    "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aggregate-innocent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['some thing even spell check cant fix', 'just woke up what an overcast day', 'rt wikileak doj assist attorney peter kadzik out as a mole for hillari clinton campaign httpstcomnhzj310nl httpstcoutqf6b', 'rt truepundit truepundit is now back on facebook go check us out amp give us a like for some exclus content httpstcoxuc0vbs3vb', 'rt distantdist enjoneer01 dubzzzinyafac itsnotawasteif you call shred anim bit a filler']\n",
      "['topnew pressur on trump like to be intens at second debat with clinton', 'gotobekiddingm i triedand fail', 'rt telcoj black trump repres bring down the hous on chicago wgn redstat httpstcou2eeoragfo', 'tonywad aww thank i dont play harp i play violin veri badli think ill stick to singingwhen i need a fanclub ill be onto you', 'rt theolcap probabletrumpstweet im not onli a client im the us presid']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(xtrain)):\n",
    "    xtrain[i] = removespchar(xtrain[i])\n",
    "    xtrain[i] = stemmer(xtrain[i])\n",
    "for i in range(len(xtest)):\n",
    "    xtest[i] = removespchar(xtest[i])\n",
    "    xtest[i] = stemmer(xtest[i])\n",
    "    \n",
    "print(xtrain[:5])\n",
    "print(xtest[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "strange-brass",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,3))\n",
    "xtrain=cv.fit_transform(xtrain)\n",
    "xtest=cv.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-income",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xtrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-romance",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "viral-macro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1]\n",
      "[1, 0, 1, 0, 1]\n",
      "Support Vector Machine Accuracy Score ->  71.23333333333333\n"
     ]
    }
   ],
   "source": [
    "svm=LinearSVC()\n",
    "svm.fit(xtrain,ytrain)\n",
    "svmpred = svm.predict(xtest)\n",
    "print(svmpred[:5])\n",
    "print(ytest[:5])\n",
    "print(\"Support Vector Machine Accuracy Score -> \",accuracy_score(svmpred, ytest)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = confusion_matrix(ytest,svmpred,labels=[1,0])\n",
    "df_cm = pd.DataFrame(array, range(2), range(2))\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "expired-tuition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 1]\n",
      "[1, 0, 1, 0, 1]\n",
      "Naive Bayes Accuracy Score ->  74.6\n"
     ]
    }
   ],
   "source": [
    "nb=naive_bayes.MultinomialNB()\n",
    "nb.fit(xtrain,ytrain)\n",
    "nbpred = nb.predict(xtest)\n",
    "print(nbpred[:5])\n",
    "print(ytest[:5])\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(nbpred, ytest)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-groove",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = confusion_matrix(ytest,nbpred,labels=[1,0])\n",
    "df_cm = pd.DataFrame(array, range(2), range(2))\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cardiovascular-gateway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1]\n",
      "[1, 0, 1, 0, 1]\n",
      "Logistic Regression Accuracy Score ->  60.71666666666666\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)\n",
    "lr.fit(xtrain,ytrain)\n",
    "lrpred = lr.predict(xtest)\n",
    "print(lrpred[:5])\n",
    "print(ytest[:5])\n",
    "print(\"Logistic Regression Accuracy Score -> \",accuracy_score(lrpred, ytest)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = confusion_matrix(ytest,lrpred,labels=[1,0])\n",
    "df_cm = pd.DataFrame(array, range(2), range(2))\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fundamental-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(cv, open(\"savedModel/sklearnpynb/BoW.sav\",\"wb\"))\n",
    "pickle.dump(nb, open(\"savedModel/sklearnpynb/nb.sav\",\"wb\"))\n",
    "pickle.dump(svm, open(\"savedModel/sklearnpynb/svm.sav\",\"wb\"))\n",
    "pickle.dump(lr, open(\"savedModel/sklearnpynb/lr.sav\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from preprocesssklearn import *\n",
    "n = int(input(\"no of sentences: \"))\n",
    "sentences = [str(input(\"enter sentence:\")) for _ in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-subsection",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    sentences[i] = removespchar(sentences[i])\n",
    "    sentences[i] = stemmer(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = pickle.load(open(\"savedModel/sklearnpynb/BoW.sav\",\"rb\"))\n",
    "nb = pickle.load(open(\"savedModel/sklearnpynb/nb.sav\",\"rb\"))\n",
    "svm = pickle.load(open(\"savedModel/sklearnpynb/svm.sav\",\"rb\"))\n",
    "lr = pickle.load(open(\"savedModel/sklearnpynb/lr.sav\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = cv.transform(sentences)\n",
    "print(svm.predict(sentences))\n",
    "print(nb.predict(sentences))\n",
    "print(lr.predict(sentences))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}